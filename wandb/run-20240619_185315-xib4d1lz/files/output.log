Using cuda device
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 20.5     |
|    ep_rew_mean     | 15.9     |
| time/              |          |
|    fps             | 780      |
|    iterations      | 1        |
|    time_elapsed    | 2        |
|    total_timesteps | 2048     |
---------------------------------

-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 28.2        |
|    ep_rew_mean          | 28.7        |
| time/                   |             |
|    fps                  | 705         |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.012912984 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.0247      |
|    learning_rate        | 0.0003      |
|    loss                 | 28.5        |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.0195     |
|    std                  | 0.995       |
|    value_loss           | 48.8        |
-----------------------------------------

-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 36.1        |
|    ep_rew_mean          | 46.5        |
| time/                   |             |
|    fps                  | 666         |
|    iterations           | 3           |
|    time_elapsed         | 9           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.012988266 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.23       |
|    explained_variance   | 0.254       |
|    learning_rate        | 0.0003      |
|    loss                 | 35.5        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0257     |
|    std                  | 0.989       |
|    value_loss           | 103         |
-----------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 43.5        |
|    ep_rew_mean          | 63.9        |
| time/                   |             |
|    fps                  | 642         |
|    iterations           | 4           |
|    time_elapsed         | 12          |
|    total_timesteps      | 8192        |
| train/                  |             |
|    approx_kl            | 0.010289911 |
|    clip_fraction        | 0.103       |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.22       |
|    explained_variance   | 0.194       |
|    learning_rate        | 0.0003      |
|    loss                 | 105         |
|    n_updates            | 30          |
|    policy_gradient_loss | -0.0166     |
|    std                  | 0.984       |
|    value_loss           | 221         |
-----------------------------------------

Eval num_timesteps=10000, episode_reward=58.32 +/- 0.75
Episode length: 35.40 +/- 0.49
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 35.4        |
|    mean_reward          | 58.3        |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.009597469 |
|    clip_fraction        | 0.0875      |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.2        |
|    explained_variance   | 0.199       |
|    learning_rate        | 0.0003      |
|    loss                 | 104         |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.0156     |
|    std                  | 0.98        |
|    value_loss           | 234         |
-----------------------------------------
New best mean reward!
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 46.8     |
|    ep_rew_mean     | 76       |
| time/              |          |
|    fps             | 627      |
|    iterations      | 5        |
|    time_elapsed    | 16       |
|    total_timesteps | 10240    |
---------------------------------
[35m   1%[39m [38mâ”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m11,281/2,000,000 [39m [ [33m0:00:18[39m < [36m0:53:14[39m , [31m623 it/s[39m ]
|    value_loss           | 309         |
|    clip_fraction        | 0.0696      |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.19       |
|    explained_variance   | 0.0713      |
|    learning_rate        | 0.0003      |
|    loss                 | 99.8        |
|    n_updates            | 50          |
|    policy_gradient_loss | -0.0116     |
|    std                  | 0.975       |
|    value_loss           | 309         |
-----------------------------------------
[35m   1%[39m [38mâ”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m13,879/2,000,000 [39m [ [33m0:00:22[39m < [36m0:52:56[39m , [31m625 it/s[39m ]
|    clip_range           | 0.2          |
|    entropy_loss         | -4.18        |
|    explained_variance   | -0.00509     |
|    learning_rate        | 0.0003       |
|    loss                 | 153          |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00902     |
|    std                  | 0.976        |
|    value_loss           | 407          |
------------------------------------------
[35m   1%[39m [38mâ”â”â•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m14,661/2,000,000 [39m [ [33m0:00:24[39m < [36m0:54:40[39m , [31m605 it/s[39m ]
|    explained_variance   | 0.00211     ||
|    ep_rew_mean          | 136         |
| time/                   |             |
|    fps                  | 616         |
|    iterations           | 8           |
|    time_elapsed         | 26          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.010326651 |
|    clip_fraction        | 0.0934      |
|    clip_range           | 0.2         |
|    entropy_loss         | -4.19       |
|    explained_variance   | 0.00211     ||
|    learning_rate        | 0.0003      |
|    loss                 | 153         |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.0115     |
|    std                  | 0.984       |
|    value_loss           | 399         |
-----------------------------------------
[35m   1%[39m [38mâ”â”â•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m17,367/2,000,000 [39m [ [33m0:00:28[39m < [36m0:53:37[39m , [31m616 it/s[39m ]
|    value_loss           | 457          |
------------------------------------------
[35m   1%[39m [38mâ”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m18,375/2,000,000 [39m [ [33m0:00:30[39m < [36m0:52:28[39m , [31m630 it/s[39m ]
|    std                  | 0.978        |
|    value_loss           | 418          |
------------------------------------------
New best mean reward!
[35m   1%[39m [38mâ”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m19,955/2,000,000 [39m [ [33m0:00:32[39m < [36m0:53:06[39m , [31m622 it/s[39m ]
|    std                  | 0.978        |
|    iterations           | 11           |
|    iterations           | 11           |
| time/                   |             ||
| time/                   |             ||
[35m   1%[39m [38mâ”â”â”â•¸â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m27,208/2,000,000 [39m [ [33m0:00:45[39m < [36m0:54:25[39m , [31m604 it/s[39m ]
|    value_loss           | 151         |
|    value_loss           | 151         |
|    std                  | 0.966        |
|    std                  | 0.966        |
|    iterations           | 16          ||
| time/                   |             ||
| time/                   |             ||
|    std                  | 0.968       ||
|    std                  | 0.968       ||
|    std                  | 0.962       ||
|    policy_gradient_loss | -0.00821     |
|    policy_gradient_loss | -0.00821     |
|    std                  | 0.96       | |
|    std                  | 0.96       | |
|    std                  | 0.963       ||
|    n_updates            | 220          |
|    n_updates            | 220          |
|    std                  | 0.966       ||
|    policy_gradient_loss | -0.0133     ||
|    policy_gradient_loss | -0.0133     ||
|    std                  | 0.973        |
|    std                  | 0.973        |
|    std                  | 0.966       ||
|    std                  | 0.966       ||
|    std                  | 0.964       ||
|    std                  | 0.964       ||
|    std                  | 0.963        |
|    std                  | 0.963        |
|    value_loss           | 115         ||
|    value_loss           | 115         ||
|    value_loss           | 115         ||
|    std                  | 0.94         |
|    std                  | 0.94         |
|    std                  | 0.932       ||
|    std                  | 0.932       ||
|    std                  | 0.926        |
|    n_updates            | 330         ||
|    n_updates            | 330         ||
|    value_loss           | 103         ||
|    value_loss           | 103         ||
|    std                  | 0.901       ||
|    std                  | 0.901       ||
|    std                  | 0.896       ||
|    std                  | 0.896       ||
|    std                  | 0.891       ||
|    n_updates            | 380         ||
|    loss                 | 92          ||
|    loss                 | 92          ||
|    loss                 | 92          ||
|    std                  | 0.883      |||
|    n_updates            | 410         ||
|    n_updates            | 410         ||
|    std                  | 0.877       ||
|    std                  | 0.877       ||
|    value_loss           | 374         ||
|    value_loss           | 374         ||
|    std                  | 0.866       ||
|    std                  | 0.866       ||
|    std                  | 0.867        |
|    n_updates            | 460         ||
|    n_updates            | 460         ||
|    std                  | 0.865       ||
|    std                  | 0.865       ||
|    value_loss           | 1.06e+03    ||
|    value_loss           | 1.06e+03    ||
|    std                  | 0.857       ||
|    n_updates            | 500         ||
|    n_updates            | 500         ||
|    std                  | 0.858      |||
|    std                  | 0.858      |||
|    std                  | 0.845       ||
|    std                  | 0.845       ||
|    value_loss           | 475          |
|    value_loss           | 475          |
/home/ale/miniconda3/envs/mldl/lib/python3.7/site-packages/stable_baselines3/common/save_util.py:278: UserWarning: Path 'Task_6/SavedModels_source' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")