Using cuda device
Eval num_timesteps=8000, episode_reward=75.81 +/- 4.55
Episode length: 83.60 +/- 4.03
New best mean reward!
Eval num_timesteps=16000, episode_reward=78.46 +/- 2.16
Episode length: 86.20 +/- 1.94
New best mean reward!
Mean reward: 77.13424309999999 +/- 4.4111573257052035 at timestep 16000
Eval num_timesteps=24000, episode_reward=76.70 +/- 3.01
Episode length: 84.80 +/- 2.79
Eval num_timesteps=32000, episode_reward=77.83 +/- 1.87
Episode length: 85.40 +/- 1.50
Mean reward: 76.09951000000001 +/- 4.588020568130682 at timestep 32000









Eval num_timesteps=40000, episode_reward=119.15 +/- 0.81
Episode length: 74.40 +/- 0.49
New best mean reward!
Eval num_timesteps=48000, episode_reward=118.79 +/- 1.30
Episode length: 74.20 +/- 0.75
Mean reward: 119.371299 +/- 1.1840514849377952 at timestep 48000
Eval num_timesteps=56000, episode_reward=119.49 +/- 0.73
Episode length: 74.60 +/- 0.49
New best mean reward!
Eval num_timesteps=64000, episode_reward=117.46 +/- 0.78
Episode length: 73.40 +/- 0.49
Mean reward: 119.85330900000001 +/- 0.9560934535001281 at timestep 64000










Eval num_timesteps=72000, episode_reward=150.36 +/- 1.09
Episode length: 73.60 +/- 0.49
New best mean reward!
Eval num_timesteps=80000, episode_reward=150.57 +/- 1.57
Episode length: 73.80 +/- 0.75
New best mean reward!
Mean reward: 150.21599790000002 +/- 1.1211565263210477 at timestep 80000
Eval num_timesteps=88000, episode_reward=151.59 +/- 1.03
Episode length: 74.20 +/- 0.40
New best mean reward!
Eval num_timesteps=96000, episode_reward=150.91 +/- 0.83
Episode length: 73.80 +/- 0.40
Mean reward: 151.44037319999998 +/- 1.5030319709388575 at timestep 96000










Eval num_timesteps=104000, episode_reward=209.95 +/- 1.00
Episode length: 90.60 +/- 0.49
New best mean reward!
Eval num_timesteps=112000, episode_reward=210.09 +/- 1.68
Episode length: 90.80 +/- 0.75
New best mean reward!
Mean reward: 210.68106889999999 +/- 1.6846938014888928 at timestep 112000
Eval num_timesteps=120000, episode_reward=210.20 +/- 0.94
Episode length: 90.80 +/- 0.40
New best mean reward!
Eval num_timesteps=128000, episode_reward=210.71 +/- 0.35
Episode length: 91.00 +/- 0.00
New best mean reward!
Mean reward: 210.2338482 +/- 1.1319148545811912 at timestep 128000

[35m 100%[39m [38mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [32m131,072/100,000 [39m [ [33m0:01:21[39m < [36m0:00:00[39m , [31m1,359 it/s[39m ]
[?25h